{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Optional Lab - Neurons and Layers\n",
    "In this lab we will explore the inner workings of neurons/units and layers. In particular, the lab will draw parallels to the models you have mastered in Course 1, the regression/linear model and the logistic model. The lab will introduce Tensorflow and demonstrate how these models are implemented in that framework.\n",
    "<figure>\n",
    "   <img src=\"./images/C2_W1_NeuronsAndLayers.png\"  style=\"width:540px;height:200px;\" >\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "**Tensorflow and Keras**  \n",
    "Tensorflow is a machine learning package developed by Google. In 2019, Google integrated Keras into Tensorflow and released Tensorflow 2.0. Keras is a framework developed independently by FranÃ§ois Chollet that creates a simple, layer-centric interface to Tensorflow. This course will be using the Keras interface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "the 'package' argument is required to perform a relative import for './deeplearning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MeanSquaredError, BinaryCrossentropy\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sigmoid\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlab_utils_common\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dlc\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlab_neurons_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plt_prob_1d, sigmoidnp, plt_linear, plt_logistic\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# plt.style.use('./deeplearning.mplstyle')\u001b[39;00m\n",
      "File \u001b[1;32mD:\\BaiduSyncdisk\\workspace\\JupyterLab\\MachineLearning\\Advanced Learning Algorithms\\week1\\work\\lab_utils_common.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m dlblue \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#0096ff\u001b[39m\u001b[38;5;124m'\u001b[39m; dlorange \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#FF9300\u001b[39m\u001b[38;5;124m'\u001b[39m; dldarkred\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#C00000\u001b[39m\u001b[38;5;124m'\u001b[39m; dlmagenta\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#FF40FF\u001b[39m\u001b[38;5;124m'\u001b[39m; dlpurple\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#7030A0\u001b[39m\u001b[38;5;124m'\u001b[39m; dldarkblue \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#0D5BDC\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m dlcolors \u001b[38;5;241m=\u001b[39m [dlblue, dlorange, dldarkred, dlmagenta, dlpurple]\n\u001b[1;32m---> 22\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstyle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./deeplearning.mplstyle\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid\u001b[39m(z):\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m    Compute the sigmoid of z\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m         sigmoid(z)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Environment\\anaconda3\\lib\\site-packages\\matplotlib\\style\\core.py:153\u001b[0m, in \u001b[0;36muse\u001b[1;34m(style)\u001b[0m\n\u001b[0;32m    151\u001b[0m pkg, _, name \u001b[38;5;241m=\u001b[39m style\u001b[38;5;241m.\u001b[39mrpartition(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     path \u001b[38;5;241m=\u001b[39m (\u001b[43mimportlib_resources\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpkg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m             \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTYLE_EXTENSION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    155\u001b[0m     style \u001b[38;5;241m=\u001b[39m _rc_params_in_file(path)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mIOError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# There is an ambiguity whether a dotted name refers to a\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# package.style_name or to a dotted file path.  Currently,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# either use Path objects or be prepended with \"./\" and use\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# the slash as marker for file paths.\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Environment\\anaconda3\\lib\\importlib\\_common.py:22\u001b[0m, in \u001b[0;36mfiles\u001b[1;34m(package)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfiles\u001b[39m(package):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# type: (Package) -> Traversable\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;124;03m    Get a Traversable resource from a package\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_package(\u001b[43mget_package\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mD:\\Environment\\anaconda3\\lib\\importlib\\_common.py:66\u001b[0m, in \u001b[0;36mget_package\u001b[1;34m(package)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_package\u001b[39m(package):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# type: (Package) -> types.ModuleType\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;124;03m\"\"\"Take a package name or module object and return the module.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[38;5;124;03m    Raise an exception if the resolved module is not a package.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     resolved \u001b[38;5;241m=\u001b[39m \u001b[43mresolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_spec(resolved)\u001b[38;5;241m.\u001b[39msubmodule_search_locations \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not a package\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Environment\\anaconda3\\lib\\importlib\\_common.py:57\u001b[0m, in \u001b[0;36mresolve\u001b[1;34m(cand)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresolve\u001b[39m(cand):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# type: (Package) -> types.ModuleType\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cand \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cand, types\u001b[38;5;241m.\u001b[39mModuleType) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Environment\\anaconda3\\lib\\importlib\\__init__.py:121\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m package:\n\u001b[0;32m    119\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpackage\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m argument is required to perform a relative \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport for \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m character \u001b[38;5;129;01min\u001b[39;00m name:\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m character \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: the 'package' argument is required to perform a relative import for './deeplearning'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from lab_utils_common import dlc\n",
    "from lab_neurons_utils import plt_prob_1d, sigmoidnp, plt_linear, plt_logistic\n",
    "# plt.style.use('./deeplearning.mplstyle')\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron without activation - Regression/Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DataSet\n",
    "We'll use an example from Course 1, linear regression on house prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = np.array([[1.0], [2.0]], dtype=np.float32)           #(size in 1000 square feet)\n",
    "Y_train = np.array([[300.0], [500.0]], dtype=np.float32)       #(price in 1000s of dollars)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.scatter(X_train, Y_train, marker='x', c='r', label=\"Data Points\")\n",
    "ax.legend( fontsize='xx-large')\n",
    "ax.set_ylabel('Price (in 1000s of dollars)', fontsize='xx-large')\n",
    "ax.set_xlabel('Size (1000 sqft)', fontsize='xx-large')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression/Linear Model \n",
    "The function implemented by a neuron with no activation is the same as in Course 1, linear regression:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = \\mathbf{w}\\cdot x^{(i)} + b \\tag{1}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a layer with one neuron or unit and compare it to the familiar linear regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = tf.keras.layers.Dense(units=1, activation = 'linear', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no weights as the weights are not yet instantiated. Let's try the model on one example in `X_train`. This will trigger the instantiation of the weights. Note, the input to the layer must be 2-D, so we'll reshape it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1,1))\n",
    "print(a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a tensor (another name for an array) with a shape of (1,1) or one entry.   \n",
    "Now let's look at the weights and bias. These weights are randomly initialized to small numbers and the bias defaults to being initialized to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b= linear_layer.get_weights()\n",
    "print(f\"w = {w}, b={b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear regression model (1) with a single input feature will have a single weight and bias. This matches the dimensions of our `linear_layer` above.   \n",
    "\n",
    "The weights are initialized to random values so let's set them to some known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_w = np.array([[200]])\n",
    "set_b = np.array([100])\n",
    "\n",
    "# set_weights takes a list of numpy arrays\n",
    "linear_layer.set_weights([set_w, set_b])\n",
    "print(linear_layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare equation (1) to the layer output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m a1 \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_layer\u001b[49m(X_train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(a1)\n\u001b[0;32m      3\u001b[0m alin \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(set_w,X_train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m set_b\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_layer' is not defined"
     ]
    }
   ],
   "source": [
    "a1 = linear_layer(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "alin = np.dot(set_w,X_train[0].reshape(1,1)) + set_b\n",
    "print(alin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They produce the same values!\n",
    "Now, we can use our linear layer to make predictions on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linear_layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prediction_tf \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_layer\u001b[49m(X_train)\n\u001b[0;32m      2\u001b[0m prediction_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot( X_train, set_w) \u001b[38;5;241m+\u001b[39m set_b\n",
      "\u001b[1;31mNameError\u001b[0m: name 'linear_layer' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_tf = linear_layer(X_train)\n",
    "prediction_np = np.dot( X_train, set_w) + set_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt_linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt_linear\u001b[49m(X_train, Y_train, prediction_tf, prediction_np)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt_linear' is not defined"
     ]
    }
   ],
   "source": [
    "plt_linear(X_train, Y_train, prediction_tf, prediction_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron with Sigmoid activation\n",
    "The function implemented by a neuron/unit with a sigmoid activation is the same as in Course 1, logistic  regression:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = g(\\mathbf{w}x^{(i)} + b) \\tag{2}$$\n",
    "where $$g(x) = sigmoid(x)$$ \n",
    "\n",
    "Let's set $w$ and $b$ to some known values and check the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DataSet\n",
    "We'll use an example from Course 1, logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1,1)  # 2-D Matrix\n",
    "Y_train = np.array([0,  0, 0, 1, 1, 1], dtype=np.float32).reshape(-1,1)  # 2-D Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 4., 5.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "X_train[pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dlc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m fig,ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m3\u001b[39m))\n\u001b[0;32m      5\u001b[0m ax\u001b[38;5;241m.\u001b[39mscatter(X_train[pos], Y_train[pos], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m80\u001b[39m, c \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my=1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m ax\u001b[38;5;241m.\u001b[39mscatter(X_train[neg], Y_train[neg], marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my=0\u001b[39m\u001b[38;5;124m\"\u001b[39m, facecolors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m----> 7\u001b[0m               edgecolors\u001b[38;5;241m=\u001b[39m\u001b[43mdlc\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdlblue\u001b[39m\u001b[38;5;124m\"\u001b[39m],lw\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m      9\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylim(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.08\u001b[39m,\u001b[38;5;241m1.1\u001b[39m)\n\u001b[0;32m     10\u001b[0m ax\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dlc' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos = Y_train == 1\n",
    "neg = Y_train == 0\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "ax.scatter(X_train[pos], Y_train[pos], marker='x', s=80, c = 'red', label=\"y=1\")\n",
    "ax.scatter(X_train[neg], Y_train[neg], marker='o', s=100, label=\"y=0\", facecolors='none', \n",
    "              edgecolors=dlc[\"dlblue\"],lw=3)\n",
    "\n",
    "ax.set_ylim(-0.08,1.1)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_title('one variable plot')\n",
    "ax.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Neuron\n",
    "We can implement a 'logistic neuron' by adding a sigmoid activation. The function of the neuron is then described by (2) above.   \n",
    "This section will create a Tensorflow Model that contains our logistic layer to demonstrate an alternate method of creating models. Tensorflow is most often used to create multi-layer models. The [Sequential](https://keras.io/guides/sequential_model/) model is a convenient means of constructing these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(1, input_dim=1,  activation = 'sigmoid', name='L1')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`model.summary()` shows the layers and number of parameters in the model. There is only one layer in this model and that layer has only one unit. The unit has two parameters, $w$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2 (8.00 Byte)\n",
      "Trainable params: 2 (8.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.85]] [0.]\n",
      "(1, 1) (1,)\n"
     ]
    }
   ],
   "source": [
    "logistic_layer = model.get_layer('L1')\n",
    "w,b = logistic_layer.get_weights()\n",
    "print(w,b)\n",
    "print(w.shape,b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the weight and bias to some known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2.]], dtype=float32), array([-4.5], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "set_w = np.array([[2]])\n",
    "set_b = np.array([-4.5])\n",
    "# set_weights takes a list of numpy arrays\n",
    "logistic_layer.set_weights([set_w, set_b])\n",
    "print(logistic_layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare equation (2) to the layer output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "[[0.01]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sigmoidnp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m a1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(a1)\n\u001b[1;32m----> 3\u001b[0m alog \u001b[38;5;241m=\u001b[39m \u001b[43msigmoidnp\u001b[49m(np\u001b[38;5;241m.\u001b[39mdot(set_w,X_train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m+\u001b[39m set_b)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(alog)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sigmoidnp' is not defined"
     ]
    }
   ],
   "source": [
    "a1 = model.predict(X_train[0].reshape(1,1))\n",
    "print(a1)\n",
    "alog = sigmoidnp(np.dot(set_w,X_train[0].reshape(1,1)) + set_b)\n",
    "print(alog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They produce the same values!\n",
    "Now, we can use our logistic layer and NumPy model to make predictions on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt_logistic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt_logistic\u001b[49m(X_train, Y_train, model, set_w, set_b, pos, neg)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt_logistic' is not defined"
     ]
    }
   ],
   "source": [
    "plt_logistic(X_train, Y_train, model, set_w, set_b, pos, neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shading above reflects the output of the sigmoid which varies from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "You built a very simple neural network and have explored the similarities of a neuron to the linear and logistic regression from Course 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
